"""
Streamlit UI - AI Image Filter Pipeline
"""

import streamlit as st
import requests
import pandas as pd
from PIL import Image
import io
import time
from datetime import datetime

# ============ ì„¤ì • ============
API_URL = "http://localhost:8000/api/v1"  # FastAPI ì„œë²„ ì£¼ì†Œ

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI Image Filter Pipeline",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============ CSS ìŠ¤íƒ€ì¼ ============
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .verdict-ai {
        background-color: #ffcccb;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #dc3545;
    }
    .verdict-real {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #28a745;
    }
    .verdict-uncertain {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #ffc107;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)


def main():
    # í—¤ë”
    st.markdown('<p class="main-header">ğŸ” AI Image Filter Pipeline</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ML í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ AI ìƒì„± ì´ë¯¸ì§€ë¥¼ í•„í„°ë§í•˜ëŠ” 3-Layer ê²€ì¦ ì‹œìŠ¤í…œ</p>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        api_url = st.text_input("API URL", value=API_URL)
        skip_ai_detection = st.checkbox("AI íƒì§€ ìŠ¤í‚µ (ë¹ ë¥¸ ë¶„ì„)", value=False)
        
        st.divider()
        
        st.header("ğŸ“Š ë¶„ì„ íŒŒì´í”„ë¼ì¸")
        st.markdown("""
        **Layer 1**: DinoV2 Hash Check
        - facebook/dinov2-small ë²¡í„° ìœ ì‚¬ë„

        **Layer 2**: Metadata Analysis
        - EXIF ì§„ìœ„ì„± ì ìˆ˜
        - EXIF ë¹„ì •ìƒ íŒ¨í„´ íƒì§€
        - C2PA Content Credentials
        - AI ë„êµ¬ ì‹œê·¸ë‹ˆì²˜

        **Layer 3**: AI Detection
        - [HuggingFace Model](https://huggingface.co/dima806/ai_vs_human_generated_image_detection)
        """)
        st.info("â„¹ï¸ Stateless ëª¨ë“œ - ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ë¶„ì„ì€ ì‹¤ì‹œê°„ìœ¼ë¡œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        
        st.divider()
        

    
    # ë©”ì¸ íƒ­
    tab1, tab2 = st.tabs(["ğŸ“¤ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„", "ğŸ“¦ ë°°ì¹˜ ë¶„ì„"])
    
    # ============ íƒ­ 1: ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ ============
    with tab1:
        st.header("ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„")
        
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "webp", "gif"],
            key="single_upload"
        )
        
        if uploaded_file:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("ğŸ“· ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
                image = Image.open(uploaded_file)
                st.image(image, use_container_width=True)
                st.caption(f"íŒŒì¼ëª…: {uploaded_file.name} | í¬ê¸°: {uploaded_file.size:,} bytes")
            
            with col2:
                st.subheader("ğŸ”¬ ë¶„ì„ ê²°ê³¼")
                
                if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", key="analyze_single"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        try:
                            # API í˜¸ì¶œ
                            uploaded_file.seek(0)
                            files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                            params = {"skip_ai_detection": skip_ai_detection}
                            
                            response = requests.post(
                                f"{api_url}/analyze",
                                files=files,
                                params=params,
                                timeout=60
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                display_result(result)
                            else:
                                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {response.text}")
                                
                        except requests.exceptions.ConnectionError:
                            st.error("âš ï¸ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                            st.info("ë¡œì»¬ í…ŒìŠ¤íŠ¸: `uvicorn app.main:app --reload`")
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ============ íƒ­ 2: ë°°ì¹˜ ë¶„ì„ ============
    with tab2:
        st.header("ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„")
        st.info("ìµœëŒ€ 50ê°œ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        uploaded_files = st.file_uploader(
            "ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png", "webp"],
            accept_multiple_files=True,
            key="batch_upload"
        )
        
        if uploaded_files:
            st.write(f"ğŸ“ {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
            
            if st.button("ğŸš€ ë°°ì¹˜ ë¶„ì„ ì‹œì‘", type="primary", key="analyze_batch"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                results = []
                
                for i, file in enumerate(uploaded_files):
                    status_text.text(f"ë¶„ì„ ì¤‘: {file.name} ({i+1}/{len(uploaded_files)})")
                    
                    try:
                        file.seek(0)
                        files = {"file": (file.name, file.getvalue(), file.type)}
                        params = {"skip_ai_detection": skip_ai_detection}
                        
                        response = requests.post(
                            f"{api_url}/analyze",
                            files=files,
                            params=params,
                            timeout=60
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            metadata = result.get("metadata_result", {})
                            hash_res = result.get("hash_result", {})
                            results.append({
                                "íŒŒì¼ëª…": file.name,
                                "íŒì •": result.get("final_verdict", "unknown"),
                                "í™•ì‹ ë„": f"{result.get('confidence_score', 0):.1%}",
                                "DinoV2 ìœ ì‚¬ë„": f"{hash_res.get('similarity', 0):.1%}",
                                "EXIF ì§„ìœ„ì„±": f"{metadata.get('exif_authenticity_score', 0):.2f}",
                                "AI ì‹œê·¸ë‹ˆì²˜": ", ".join(metadata.get("ai_tool_signatures", [])) or "-",
                                "EXIF ë¹„ì •ìƒ": len(metadata.get("exif_inconsistencies", []))
                            })
                        else:
                            results.append({
                                "íŒŒì¼ëª…": file.name,
                                "íŒì •": "error",
                                "í™•ì‹ ë„": "-",
                                "DinoV2 ìœ ì‚¬ë„": "-",
                                "EXIF ì§„ìœ„ì„±": "-",
                                "AI ì‹œê·¸ë‹ˆì²˜": "-",
                                "EXIF ë¹„ì •ìƒ": "-"
                            })
                    except Exception as e:
                        results.append({
                            "íŒŒì¼ëª…": file.name,
                            "íŒì •": "error",
                            "í™•ì‹ ë„": "-",
                            "DinoV2 ìœ ì‚¬ë„": "-",
                            "EXIF ì§„ìœ„ì„±": "-",
                            "AI ì‹œê·¸ë‹ˆì²˜": str(e)[:30],
                            "EXIF ë¹„ì •ìƒ": "-"
                        })
                    
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                # ê²°ê³¼ í…Œì´ë¸”
                df = pd.DataFrame(results)
                st.dataframe(df, use_container_width=True)
                
                # í†µê³„
                col1, col2, col3 = st.columns(3)
                ai_count = sum(1 for r in results if r["íŒì •"] == "ai_generated")
                real_count = sum(1 for r in results if r["íŒì •"] == "likely_real")
                uncertain_count = sum(1 for r in results if r["íŒì •"] == "uncertain")
                
                col1.metric("ğŸ¤– AI ìƒì„±", ai_count)
                col2.metric("âœ… ì‹¤ì œ ì´ë¯¸ì§€", real_count)
                col3.metric("â“ ë¶ˆí™•ì‹¤", uncertain_count)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    "ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    csv,
                    f"ai_filter_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    "text/csv"
                )
    



def display_result(result: dict):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    verdict = result.get("final_verdict", "unknown")
    confidence = result.get("confidence_score", 0)
    
    # íŒì • ê²°ê³¼ í‘œì‹œ
    if verdict == "ai_generated":
        st.markdown(f"""
        <div class="verdict-ai">
            <h3>ğŸ¤– AI ìƒì„± ì´ë¯¸ì§€ë¡œ íŒì •</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    elif verdict == "likely_real":
        st.markdown(f"""
        <div class="verdict-real">
            <h3>âœ… ì‹¤ì œ ì´ë¯¸ì§€ë¡œ íŒì •</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="verdict-uncertain">
            <h3>â“ íŒì • ë¶ˆí™•ì‹¤</h3>
            <p>í™•ì‹ ë„: <strong>{confidence:.1%}</strong></p>
        </div>
        """, unsafe_allow_html=True)
    
    st.divider()
    
    # ìƒì„¸ ê²°ê³¼
    with st.expander("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼", expanded=True):
        # íŒì • ê·¼ê±°
        st.subheader("íŒì • ê·¼ê±°")
        reasoning = result.get("reasoning", "")
        for reason in reasoning.split(" | "):
            st.write(f"â€¢ {reason}")
        
        st.divider()
        
        # Layer 1: Hash Check (DinoV2)
        st.subheader("Layer 1: Hash Check (DinoV2)")
        hash_result = result.get("hash_result", {})
        col1, col2 = st.columns(2)
        with col1:
            similarity = hash_result.get('similarity', 0)
            st.metric("DinoV2 ìœ ì‚¬ë„", f"{similarity:.1%}")
        with col2:
            is_ai = hash_result.get("is_ai", False)
            if is_ai:
                st.error("âš ï¸ AI ì´ë¯¸ì§€ DB ë§¤ì¹­")
            else:
                st.success("âœ“ DB ë¯¸ë“±ë¡")
        
        st.divider()
        
        # Layer 2: Metadata Analysis
        st.subheader("Layer 2: Metadata Analysis")
        metadata = result.get("metadata_result", {})

        # EXIF ì§„ìœ„ì„± ì ìˆ˜ (ìƒˆë¡œ ì¶”ê°€)
        col1, col2, col3 = st.columns(3)
        with col1:
            exif_score = metadata.get("exif_authenticity_score", 0)
            st.metric("EXIF ì§„ìœ„ì„±", f"{exif_score:.2f}")
            if exif_score >= 0.7:
                st.success("ğŸ“· ì‹¤ì œ ì¹´ë©”ë¼ ì´¬ì˜ ê°€ëŠ¥ì„±")
            elif exif_score >= 0.3:
                st.info("ğŸ“· ì¤‘ê°„ ìˆ˜ì¤€")
            else:
                st.warning("âš ï¸ AI ìƒì„± ì˜ì‹¬")

        with col2:
            if metadata.get("has_c2pa"):
                st.success("ğŸ“œ C2PA ì¡´ì¬")
            else:
                st.info("ğŸ“œ C2PA ì—†ìŒ")

        with col3:
            sig_count = len(metadata.get("ai_tool_signatures", []))
            if sig_count > 0:
                st.error(f"ğŸ” AI ì‹œê·¸ë‹ˆì²˜: {sig_count}ê°œ")
            else:
                st.success("âœ“ AI ì‹œê·¸ë‹ˆì²˜ ì—†ìŒ")

        # EXIF ë¹„ì •ìƒ íŒ¨í„´ (ìƒˆë¡œ ì¶”ê°€)
        exif_inconsistencies = metadata.get("exif_inconsistencies", [])
        if exif_inconsistencies:
            st.warning("âš ï¸ **EXIF ë¹„ì •ìƒ íŒ¨í„´ íƒì§€:**")
            inconsistency_msgs = {
                "editing_software_without_camera": "í¸ì§‘ ì†Œí”„íŠ¸ì›¨ì–´ë§Œ ì¡´ì¬ (ì¹´ë©”ë¼ ì •ë³´ ì—†ìŒ)",
                "perfect_square_ai_resolution": "AI ìƒì„± íŠ¹ì§•ì  í•´ìƒë„ (512x512, 1024x1024 ë“±)",
                "unrealistic_aperture": "ë¹„í˜„ì‹¤ì ì¸ ì¡°ë¦¬ê°œ ê°’",
                "missing_datetime_original": "ì›ë³¸ ì´¬ì˜ ì‹œê°„ ì •ë³´ ëˆ„ë½"
            }
            for inc in exif_inconsistencies:
                st.write(f"  â€¢ {inconsistency_msgs.get(inc, inc)}")

        # ìƒì„¸ ì •ë³´
        st.markdown("**ìƒì„¸ ì •ë³´:**")

        if metadata.get("ai_tool_signatures"):
            st.warning(f"ğŸ” AI ë„êµ¬: {', '.join(metadata['ai_tool_signatures'])}")

        if metadata.get("software_used"):
            st.info(f"ğŸ’» ì†Œí”„íŠ¸ì›¨ì–´: {metadata['software_used']}")

        if metadata.get("creation_date"):
            st.info(f"ğŸ“… ì´¬ì˜/ìƒì„± ë‚ ì§œ: {metadata['creation_date']}")

        if metadata.get("exif_data"):
            with st.expander("ğŸ“Š ì „ì²´ EXIF ë°ì´í„° ë³´ê¸°"):
                exif_data = metadata["exif_data"]
                # ì£¼ìš” í•„ë“œë§Œ ë¨¼ì € í‘œì‹œ
                important_fields = ["Make", "Model", "Software", "DateTime", "DateTimeOriginal",
                                   "ExposureTime", "FNumber", "ISOSpeedRatings", "FocalLength"]
                important_data = {k: v for k, v in exif_data.items() if k in important_fields}
                if important_data:
                    st.markdown("**ì£¼ìš” EXIF ì •ë³´:**")
                    st.json(important_data)

                st.markdown("**ì „ì²´ EXIF ë°ì´í„°:**")
                st.json(exif_data)
        
        st.divider()
        
        # Layer 3: AI Detection
        st.subheader("Layer 3: AI Detection")
        detection = result.get("detection_result")
        if detection:
            st.write(f"**ëª¨ë¸**: {detection.get('model_name', 'N/A')}")
            st.write(f"**AI ìƒì„± íŒì •**: {'ì˜ˆ' if detection.get('is_ai_generated') else 'ì•„ë‹ˆì˜¤'}")
            st.write(f"**í™•ì‹ ë„**: {detection.get('confidence', 0):.1%}")
            
            if detection.get("raw_scores"):
                st.write("**Raw Scores:**")
                for label, score in detection["raw_scores"].items():
                    st.progress(score, text=f"{label}: {score:.1%}")
        else:
            st.info("AI íƒì§€ ìŠ¤í‚µë¨")
    
    # ì‹¤í–‰ ì‹œê°„
    st.caption(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {result.get('total_execution_time_ms', 0):.0f}ms")


if __name__ == "__main__":
    main()
